{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Pipelines\n",
    "\n",
    "Put on your Super Mario hats because we are going to dive into some pipelines!\n",
    "\n",
    "## What will we accomplish\n",
    "\n",
    "In this notebook we will:\n",
    "- Introduce the concept of a pipeline,\n",
    "- Review `sklearn`'s `Pipeline`s and\n",
    "- Fit a polynomial regression using `PolynomialFeatures` and `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a pipeline?\n",
    "\n",
    "We have done a little bit of data preprocessing up to this point including, scaling and creating new features out of existing features (e.g. polynomial transforms, one-hot encoding and interactions). The concept of a <i>pipeline</i> is a nice framework for combining all of those steps and fitting a model all into one container. Here's a simple visualization that helps explain this concept:\n",
    "\n",
    "<img src=\"lecture_assets/pipe.png\" style=\"width:85%\"></img>\n",
    "\n",
    "<i>Mario of the Super Mario Brothers video game franchise is intellectual property of the Nintendo Corporation</i>.\n",
    "\n",
    "## An example in python\n",
    "\n",
    "Let's show how to implement this concept in python by doing an example problem. We will create some synthetic data where we would like to fit a polynomial regression model. \n",
    "\n",
    "In this example we will introduce:\n",
    "- `PolynomialFeatures`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html</a> and \n",
    "- `Pipeline`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(216)\n",
    "\n",
    "## Generating some data\n",
    "x = np.linspace(-3,7.5,1000)\n",
    "y = (x-7)*(x+2)*x + 10*rng.standard_normal(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstrating the data\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.scatter(x,y, s=10)\n",
    "\n",
    "plt.xlabel(\"$x$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our pipeline we will want to transform $x$ into $x$, $x^2$ and $x^3$ and then use the resulting data to fit the model\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\epsilon.\n",
    "$$\n",
    "\n",
    "Schematically our pipe will look like this:\n",
    "\n",
    "<img src=\"lecture_assets/pipe_example.png\" width=\"60%\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the Pipeline object\n",
    "## Pipeline objects take in a list as an argument\n",
    "## that list contains tuples of the steps you want in your pipeline\n",
    "## In this tuple we want PolynomialFeatures and\n",
    "## LinearRegression\n",
    "## Each tuple has a name for the step as its first entry,\n",
    "## then the python object as its second entry\n",
    "pipe = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline`'s also have a `fit` method. This is what runs the input and output data through the pipe and fits all relevant transformers and scalers followed by the model. We can call it like we have done for scaler and transformer object `fit` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x.reshape(-1,1), y, shuffle= True, random_state=216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit the Pipeline object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the pipe is fit we can make predictions like we would for a normal `LinearRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show we can make predictions\n",
    "pipe.predict([[0],[1],[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstrating the data\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.scatter(x_train,y_train,alpha=.5,s=10, color = \"blue\", label = \"train\")\n",
    "plt.scatter(x_test,y_test,alpha=.5,s=10, color = \"orange\", label = \"test\")\n",
    "plt.plot(np.linspace(-3,8,100), \n",
    "         pipe.predict(np.linspace(-3,8,100).reshape(-1,1)),\n",
    "         'k',\n",
    "         linewidth=2)\n",
    "\n",
    "plt.xlabel(\"$x$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", fontsize=18)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the individual pieces of the pipe and see what is going on in them. Below we access the fit `LinearRegression` object and look at the resulting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show how to access individual components of Pipeline\n",
    "## This is done similar to how a dictionary is accessed.\n",
    "pipe['reg'].intercept_, pipe['reg'].coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we originally generated this data using  $y = (x-7)(x+2)x + \\epsilon$.  \n",
    "So $y \\approx -14x -5x^2 + x^3$.  \n",
    "We did pretty well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a good introduction to `Pipeline`s. Note that while we did not use a `scaler` object, we could have. This particular problem just did not call for scaling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.  Modified by Steven Gubkin 2024.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
