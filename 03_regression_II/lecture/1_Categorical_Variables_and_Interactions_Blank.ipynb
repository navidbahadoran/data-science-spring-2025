{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59eb75f9",
   "metadata": {},
   "source": [
    "# Categorical Variables and Interactions\n",
    "\n",
    "We continue our work with multiple linear regression by showing how to include categorical variables and interaction terms into your regression model.\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "We will:\n",
    "- Introduce a data set,\n",
    "- Show how to incorporate categorical variables into multiple linear regression,\n",
    "- Demonstrate one-hot encoding in python and\n",
    "- Discuss interaction terms and how they affect your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69abccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import some packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dbb5b9",
   "metadata": {},
   "source": [
    "## A new data set\n",
    "\n",
    "Let us start by loading in a new data set, `beer1.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8503d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data\n",
    "## note you may need to change the path if you\n",
    "## are running Windows\n",
    "beer = pd.read_csv(\"../../data/beer1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the train test split\n",
    "## ignore stratify for now, you will have a problem\n",
    "## session question about it\n",
    "beer_train, beer_test = train_test_split(beer.copy(), \n",
    "                                            shuffle=True,\n",
    "                                            random_state=614,\n",
    "                                            stratify=beer['Beer_Type'], # This preserves the fraction of each type in both train and test.\n",
    "                                            test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_train.sample(5, random_state=440)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab82f59",
   "metadata": {},
   "source": [
    "As we can see, this data set contains information on various beers. It includes the beer's `IBU` (international bitterness units), `ABV` (alcohol by volume), user `Rating` and the type of the beer. In this notebook we will focus on building models to predict the beer's `IBU`. It's reasonable to assume that `Rating` has no bearing on the `IBU` value for a particular beer, same for the name. So moving forward we will focus on the `ABV` and `Beer_Type` as potential features.\n",
    "\n",
    "Let's look at any potential relationship between `IBU` and `ABV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.scatter(beer_train.ABV,\n",
    "               beer_train.IBU)\n",
    "\n",
    "plt.xlabel(\"ABV\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53112be",
   "metadata": {},
   "source": [
    "There appears to be positive linear relationship between `ABV` and `IBU`. Our first two models will thus be the simple baseline and a simple linear regression regressing `IBU` on `ABV`.\n",
    "\n",
    "##### Baseline model\n",
    "\n",
    "$$\n",
    "\\text{IBU} = E(\\text{IBU}) + \\epsilon\n",
    "$$\n",
    "\n",
    "##### Simple linear regression model\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290210e",
   "metadata": {},
   "source": [
    "## Categorical variables\n",
    "\n",
    "Now let's investigate if `Beer_Type` seems to have any impact on `IBU`. One way to do this is to look at some plots.\n",
    "\n",
    "A nice plot to use is `seaborn`'s `swarmplot`, <a href=\"https://seaborn.pydata.org/generated/seaborn.swarmplot.html\">https://seaborn.pydata.org/generated/seaborn.swarmplot.html</a>. This plots each observation as a dot according to the value it has for the desired feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf08640",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure object\n",
    "plt.figure(figsize=(4,6))\n",
    "\n",
    "## Call swarmplot\n",
    "## First put in the dataframe in data = \n",
    "## Then what you want on the x and y axis\n",
    "## Finally, palette, an optional input, allows me to color the points\n",
    "sns.swarmplot(data=beer_train,\n",
    "               x = 'Beer_Type',\n",
    "               y = 'IBU',\n",
    "            hue='Beer_Type',\n",
    "            palette=['blue', 'orange'],\n",
    "            legend=False)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(\"Beer Type\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78e923",
   "metadata": {},
   "source": [
    "If possible, we can also recreate the scatter plot from before, this time colored by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='IPA'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='IPA'].IBU,\n",
    "               label=\"IPAs\",\n",
    "               marker='v',\n",
    "               s=60,\n",
    "               edgecolor='black',\n",
    "               c='orange')\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='Stout'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='Stout'].IBU,\n",
    "               label=\"Stout\",\n",
    "               s=60,\n",
    "               edgecolor='black',\n",
    "               c='lightblue')\n",
    "\n",
    "plt.xlabel(\"ABV\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17fab3",
   "metadata": {},
   "source": [
    "In both plots there seems reason to believe that IPAs tent to have slightly higher IBUs than Stouts. Let's see how to encode this information to be used in multiple linear regression model.\n",
    "\n",
    "### One-hot encoding\n",
    "\n",
    "Currently our `Beer_Type` column is stored as a column of strings. This is great for human readability, but terrible for regression models, enter <i>one-hot encoding</i>.\n",
    "\n",
    "One-hot encoding is when you take a categorical variable and represent it as a collection of new $0-1$ variables. Suppose you have a variable, $x$, with $k$ unique categories, then one-hot encoding is the process of creating $k-1$ indicator variables:\n",
    "\n",
    "$$\n",
    "1_j = \\left\\lbrace \\begin{array}{l l} 1 & \\text{if } x=j \\\\ 0 & \\text{if } x \\neq j\\end{array} \\right., \\text{ for } j = 1, \\dots, k-1.\n",
    "$$\n",
    "\n",
    "We only need $k-1$ of these variables because of the process of elimination. If all of the $1_j=0$, then that means that $x$ is not any of $1,\\dots,k-1$ and thus it must be $k$.\n",
    "\n",
    "#### In python\n",
    "\n",
    "Let's now demonstrate how to do this in python. We will make an indicator for when a beer is a Stout, i.e.\n",
    "\n",
    "$$\n",
    "1_{\\text{Stout}} = \\left\\lbrace \\begin{array}{l l} 1 & \\text{if the beer is a Stout}  \\\\ 0 & \\text{Else} \\end{array} \\right..\n",
    "$$\n",
    "\n",
    "Since there are only two possible values we could do this by hand, but we will demonstrate a function that is useful for variables with more than two categories, `get_dummies`, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\">https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a8e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstrate it here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store the variable in beer_train here\n",
    "beer_train['Stout'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eefe95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8f2ba",
   "metadata": {},
   "source": [
    "This new indicator variable allows us to fit a third model.\n",
    "\n",
    "##### Stout model\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\beta_2 \\text{Stout} + \\epsilon\n",
    "$$\n",
    "\n",
    "Let's think about what this model is actually doing before we fit it:\n",
    "\n",
    "* When $\\text{Stout} = 0$, we have $\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\epsilon$.\n",
    "* When $\\text{Stout} = 1$, we have $\\text{IBU} = (\\beta_0 + \\beta_2) +  \\beta_1 \\text{ABV} + \\epsilon$  \n",
    "\n",
    "In other words, our modeling assumption is that a beer being a stout gives us a fixed additional $\\text{IBU}$ represented by $\\beta_2$.  A plot of the model with $\\text{Stout} = 0$ and $\\text{Stout} = 1$ would give two parallel lines.\n",
    "\n",
    "Let's quickly fit this model and plot it along with our training data. \n",
    "\n",
    "NOTE:  An alternative model way of writing this model would be \n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 \\text{Stout} + \\beta_1 \\text{IPA} + \\beta_2 \\text{ABV} + \\epsilon\n",
    "$$\n",
    "\n",
    "This model is equivalent to our model above and has a somewhat more straightforward interpretation for the model parameters:  $\\beta_0$ is the intercept for stouts, $\\beta_1$ is the intercept for IPAs, and $\\beta_2$ is the common (\"pooled\") rate of change.\n",
    "\n",
    "While I personally find this a bit easier to understand it is more conventional to set things up the way we did initially.\n",
    "\n",
    "WARNING:\n",
    "\n",
    "The model \n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{Stout} + \\beta_2 \\text{IPA} + \\beta_3 \\text{ABV} + \\epsilon\n",
    "$$\n",
    "\n",
    "has exact collinearity issues:  since $\\text{Stout} + \\text{IPA} = \\vec{1}$, the design matrix is singular.  This makes the model \"non-identifiable\": consider that the predictions returned by $(\\beta_0 + b) + (\\beta_1 - b)\\text{Stout} + (\\beta_2 - b) \\text{IPA} + \\beta_3 \\text{ABV}$ are identical for all $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce20738",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the model object\n",
    "stout_lr = LinearRegression()\n",
    "\n",
    "## Fit the model\n",
    "stout_lr.fit(beer_train[['ABV', 'Stout']],\n",
    "                beer_train['IBU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code plots that model with the training data ##\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='IPA'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='IPA'].IBU,\n",
    "               label=\"IPAs\",\n",
    "               marker='v',\n",
    "               s=60,\n",
    "               alpha=.5,\n",
    "               edgecolor='black',\n",
    "               c='orange')\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='Stout'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='Stout'].IBU,\n",
    "               label=\"Stout\",\n",
    "               s=60,\n",
    "               alpha=.5,\n",
    "               edgecolor='black',\n",
    "               c='lightblue')\n",
    "\n",
    "xs_ipa = np.zeros((1000,2))\n",
    "xs_ipa[:,0] = np.linspace(beer_train.ABV.min()-2,\n",
    "                    beer_train.ABV.max()+2,1000)\n",
    "ipa_line = stout_lr.predict(xs_ipa)\n",
    "\n",
    "xs_stout = np.ones((1000,2))\n",
    "xs_stout[:,0] = np.linspace(beer_train.ABV.min()-2,\n",
    "                    beer_train.ABV.max()+2,1000)\n",
    "stout_line = stout_lr.predict(xs_stout)\n",
    "\n",
    "\n",
    "plt.plot(xs_ipa[:,0], ipa_line,\n",
    "            '--', \n",
    "            c='orange',\n",
    "            linewidth=1.5,\n",
    "            label=\"Model Output for IPAs\")\n",
    "plt.plot(xs_stout[:,0], stout_line,\n",
    "            '-', \n",
    "            c='blue',\n",
    "            linewidth=1.5,\n",
    "            label=\"Model Output for Stouts\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"ABV\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db07f3",
   "metadata": {},
   "source": [
    "## Interaction terms\n",
    "\n",
    "As noted, the model we just fit produces lines with the same slope for IPAs and Stouts.\n",
    "\n",
    "In order to impact the slope, we must add an <i>interaction term</i> between `ABV` and `Stout`.\n",
    "\n",
    "Interaction terms are just a fancy way of saying we should multiply two variables. So here we want to multiply the `ABV` and the `Stout` column. This produces the following interaction model (our final model for this notebook):\n",
    "\n",
    "##### Interaction Model\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\beta_2 \\text{Stout} + \\beta_3 \\text{ABV} \\times \\text{Stout} + \\epsilon\n",
    "$$\n",
    "\n",
    "We can once again observe the differences for $\\text{Stout} = 0$ vs $\\text{Stout} = 1$.\n",
    "\n",
    "When $\\text{Stout}=0$ we have that:\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\epsilon,\n",
    "$$\n",
    "\n",
    "however when $\\text{Stout}=1$ we have:\n",
    "\n",
    "$$\n",
    "\\text{IBU} = (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3) \\text{ABV} + \\epsilon.\n",
    "$$\n",
    "\n",
    "In other words, $\\beta_2$ is change in the intercept, and $\\beta_3$ is the change in the slope, associated with stouts compared to IPAs.\n",
    "\n",
    "Let's visualize this quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the interaction term\n",
    "beer_train['ABV_Stout'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55837cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the model object\n",
    "interaction_lr = LinearRegression()\n",
    "\n",
    "## Fit the model\n",
    "interaction_lr.fit(beer_train[['ABV', 'Stout', 'ABV_Stout']],\n",
    "                        beer_train['IBU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code plots that model with the training data ##\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='IPA'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='IPA'].IBU,\n",
    "               label=\"IPAs\",\n",
    "               marker='v',\n",
    "               s=60,\n",
    "               alpha=.5,\n",
    "               edgecolor='black',\n",
    "               c='orange')\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='Stout'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='Stout'].IBU,\n",
    "               label=\"Stout\",\n",
    "               s=60,\n",
    "               alpha=.5,\n",
    "               edgecolor='black',\n",
    "               c='lightblue')\n",
    "xs_ipa = np.zeros((1000,3))\n",
    "xs_ipa[:,0] = np.linspace(beer_train.ABV.min()-2,\n",
    "                    beer_train.ABV.max()+2,1000)\n",
    "xs_ipa[:,2] = xs_ipa[:,0]*xs_ipa[:,1]\n",
    "ipa_line = interaction_lr.predict(xs_ipa)\n",
    "\n",
    "xs_stout = np.ones((1000,3))\n",
    "xs_stout[:,0] = np.linspace(beer_train.ABV.min()-2,\n",
    "                    beer_train.ABV.max()+2,1000)\n",
    "xs_stout[:,2] = xs_stout[:,0]*xs_stout[:,1]\n",
    "stout_line = interaction_lr.predict(xs_stout)\n",
    "\n",
    "\n",
    "plt.plot(xs_ipa[:,0], ipa_line,\n",
    "            '--', \n",
    "            c='orange',\n",
    "            linewidth=1.5,\n",
    "            label=\"Model Output for IPAs\")\n",
    "plt.plot(xs_stout[:,0], stout_line,\n",
    "            '-', \n",
    "            c='blue',\n",
    "            linewidth=1.5,\n",
    "            label=\"Model Output for Stouts\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"ABV\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324c29d",
   "metadata": {},
   "source": [
    "This looks like a better fit on the training data. However we should be cautious:  it is a fact that adding more regressors **always** decreases the MSE on the training data.\n",
    "\n",
    "So let's use cross-validation to see which of our four proposed models generalizes the best to unseen data.\n",
    "\n",
    "### Comparing all four models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9bf3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import KFold.  Note that StratifiedKFold would also be an option here, but I don't want to introduce too many new things at once.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "## import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac581250",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the KFold object.\n",
    "kfold = KFold(n_splits=5,\n",
    "                 shuffle=True,\n",
    "                 random_state=431)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = np.zeros((4, 5))\n",
    "\n",
    "## This will keep track of the split we are on\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(beer_train):\n",
    "    beer_tt = beer_train.iloc[train_index]\n",
    "    beer_ho = beer_train.iloc[test_index]\n",
    "    \n",
    "    ## baseline model\n",
    "    pred_baseline = beer_tt.IBU.mean()*np.ones(len(beer_ho))\n",
    "    \n",
    "    ## SLR model\n",
    "    slr = LinearRegression()\n",
    "    slr.fit(beer_tt[['ABV']],\n",
    "               beer_tt.IBU)\n",
    "    pred_slr = slr.predict(beer_ho[['ABV']])\n",
    "    \n",
    "    \n",
    "    ## STOUT Model\n",
    "    stout_model = LinearRegression()\n",
    "    stout_model.fit(beer_tt[['ABV', 'Stout']],\n",
    "                 beer_tt.IBU)\n",
    "    pred_stout = stout_model.predict(beer_ho[['ABV', 'Stout']])\n",
    "    \n",
    "    ## Interaction Model\n",
    "    interact_model = LinearRegression()\n",
    "    interact_model.fit(beer_tt[['ABV', 'Stout', 'ABV_Stout']],\n",
    "                       beer_tt.IBU)\n",
    "    pred_interact = interact_model.predict(beer_ho[['ABV', 'Stout', 'ABV_Stout']])\n",
    "    \n",
    "    ### record MSEs ###\n",
    "    mses[0,i] = mse(beer_ho.IBU, pred_baseline)\n",
    "    mses[1,i] = mse(beer_ho.IBU, pred_slr)\n",
    "    mses[2,i] = mse(beer_ho.IBU, pred_stout)\n",
    "    mses[3,i] = mse(beer_ho.IBU, pred_interact)\n",
    "\n",
    "    ## increase the counter\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Print the results\n",
    "print(\"The average cross-validation mse for the baseline model is\",\n",
    "                      np.round(np.mean(mses, axis=1)[0],4))\n",
    "print(\"The average cross-validation mse for the simple linear regression model is\",\n",
    "                      np.round(np.mean(mses, axis=1)[1],4))\n",
    "print(\"The average cross-validation mse for the Stout model is\",\n",
    "                      np.round(np.mean(mses, axis=1)[2],4))\n",
    "print(\"The average cross-validation mse for the interaction model is\",\n",
    "                      np.round(np.mean(mses, axis=1)[3],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943fea0b",
   "metadata": {},
   "source": [
    "The interaction model appears to have the best cross-validation performance (although the Stout model will likely give similar performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed58e82",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
