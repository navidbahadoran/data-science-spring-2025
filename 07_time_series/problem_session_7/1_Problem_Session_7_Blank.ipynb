{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Session 7\n",
    "\n",
    "In this problem session you will get some practice with:\n",
    "* $\\operatorname{AR}(p)$ models\n",
    "* $\\operatorname{MA}(q)$ models\n",
    "* Time series cross validation\n",
    "\n",
    "Question 1 and 2 use simulation to investigate $\\operatorname{AR}(p)$ and $\\operatorname{MA}(q)$ models respectively.\n",
    "\n",
    "Question 3 applies a few different models to real data.  We use time series cross validation for model selection purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Autoregressive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that an autoregressive model of order $p$ is defined as follows:\n",
    "\n",
    "The $\\operatorname{AR}(p)$ model is\n",
    "\n",
    "$$\n",
    "y_t = \\beta_1 y_{t-1} + \\beta_2 y_{t-2} + \\dots  + \\beta_p y_{t - p} + \\epsilon_t\n",
    "$$\n",
    "\n",
    "where $\\epsilon_t \\sim \\operatorname{NID}(0,\\sigma^2)$\n",
    "\n",
    "$p$ is a hyperparameter and the $\\beta_i$ and $\\sigma^2$ are parameters which need to be fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a)\n",
    "\n",
    "In this first problem we will *simulate* some $\\operatorname{AR}(2)$ data.  In particular we will simulate the following:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "y_0 &= \\epsilon_0\\\\\n",
    "y_1 &= \\epsilon_1\\\\\n",
    "y_t &= 0.5 y_{t-1} + 0.2 y_{t-2} + \\epsilon_t\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "with $\\epsilon_t \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "Write python code to simulate one realization of this process!\n",
    "\n",
    "Hint:  You will need to use `np.random.normal` and a \"for loop\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "\n",
    "# Initialize y as a numpy array of zeros of size sample_size \n",
    "y = \n",
    "\n",
    "# Assign the first two values to be draws from the standard normal distribution.\n",
    "y[0] = \n",
    "y[1] = \n",
    "\n",
    "# Implement the recursive definition of y[i]\n",
    "for i in range(2,sample_size):\n",
    "    y[i] = \n",
    "\n",
    "# Note:  I simulated 10000 times and these asserts always passed.  \n",
    "# Then I tried 100000 and one of them failed.\n",
    "# So if you fail once you can be almost certain your code is wrong.\n",
    "assert(type(y) == np.ndarray)\n",
    "assert(len(y) == sample_size)\n",
    "assert(np.abs(y.mean()) < 1)\n",
    "assert(np.abs((y[1:]*y[:-1]).mean()) > 0.5)\n",
    "assert(np.abs((y[1:]*y[:-1]).mean()) < 3)\n",
    "assert(np.abs((y[50:]*y[:-50])).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b)\n",
    "\n",
    "Plot the ACF and PACF plots of this time series.  Before making the plots, discuss what you *expect* to see with your group based on the theory covered in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c)  \n",
    "\n",
    "We will now attempt to estimate the parameters by simply regressing $y_t$ on $y_{t-1}$ and $y_{t-2}$.\n",
    "\n",
    "Write a function called `X_y_for_lags` which works as follows:\n",
    "\n",
    "$$\n",
    "\\operatorname{X\\_y\\_for\\_lags}([1,2,3,4,5,6],2) =  \\left(\n",
    "\\begin{bmatrix} \n",
    "2 & 1\\\\\n",
    "3 & 2\\\\\n",
    "4 & 3\\\\\n",
    "5 & 4\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix} 3, 4, 5, 6\\end{bmatrix} \n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Note:  I got stuck on this for quite a while myself.  I had an indexing error which was hard to resolve.  If you spend more than 5 minutes on this, just copy/paste from the solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_for_lags(ts, num_lags):\n",
    "    '''\n",
    "    Inputs\n",
    "        ts: A numpy array of size (n,) representing a time series\n",
    "        num_lags: The number of lags to include in the resulting design matrix\n",
    "\n",
    "    Outputs\n",
    "        X: A numpy array of size (n - num_lags, num_lags). \n",
    "            The first column is lag 1, second column is lag 2, etc \n",
    "        y: The time series starting at entry num_lags\n",
    "    '''\n",
    "    # Your code here\n",
    "    return X, y\n",
    "\n",
    "# Test cases\n",
    "assert np.array_equal(\n",
    "    X_y_for_lags(np.array([1., 2., 3., 4., 5., 6.]), 2)[0], \n",
    "    np.array([\n",
    "        [2., 1.], \n",
    "        [3., 2.], \n",
    "        [4., 3.], \n",
    "        [5., 4.]])\n",
    ")\n",
    "\n",
    "assert np.array_equal(\n",
    "    X_y_for_lags(np.array([1., 2., 3., 4., 5., 6.]), 2)[1], \n",
    "    np.array([3., 4., 5., 6.])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit a linear regression model to estimate the parameters.  How close do you get to recovering the parameters (which were $0.5$ and $0.2$)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the linear regression model\n",
    "ar_model = \n",
    "\n",
    "# Fit the model\n",
    "\n",
    "# Look at the coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing this manually, we can instead use a python package which can handle $\\operatorname{AR}(p)$ model estimation.  One such package is `pmdarima`, which wraps statsmodels ARIMA packages.\n",
    "\n",
    "ARIMA stands for AutoRegressive Moving Averages.  We can use ARIMA with just the AR part for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pm.ARIMA` has a kwarg called `order`.  If we set `order = (p,d,q)` then our ARIMA model has \n",
    "\n",
    "* An $\\operatorname{AR}(p)$ component \n",
    "* Has been differenced $d$ times before estimation (and so needs to be \"Integrated\" $d$ times)\n",
    "* Has an $\\operatorname{MA}(q)$ component.\n",
    "\n",
    "So we can fit an $\\operatorname{AR}(2)$ model using `order = (2,0,0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = pm.ARIMA(order=(2, 0, 0))\n",
    "arima.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima.params()[[1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be close to what we got using linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It might be interesting to \"run all cells above\" \n",
    "# a few times to see the variability in parameter estimates.\n",
    "# Note that this is 1000 time points from a series we *know* follows an  \n",
    "# AR(2) process.  You can imagine how hard it is to estimate these things \n",
    "# on real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Moving Average models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\operatorname{MA}(q)$ model is\n",
    "\n",
    "$$\n",
    "y_t = \\epsilon_t + \\alpha_1 \\epsilon_{t-1} + \\alpha_2 \\epsilon_{t-2} + \\dots + \\alpha_q \\epsilon_{t-q}\n",
    "$$\n",
    "\n",
    "where $\\epsilon_t \\sim \\operatorname{NID}(0,\\sigma^2)$\n",
    "\n",
    "$q$ is a hyperparameter and the $\\alpha_i$ and $\\sigma^2$ are parameters which need to be fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a)\n",
    "\n",
    "We will simulate some $\\operatorname{MA}(2)$ data.  In particular we will simulate the following:\n",
    "\n",
    "$$\n",
    "y_t = \\epsilon_t + 0.5\\epsilon_{t-1} + 0.2\\epsilon_{t-2}\n",
    "$$\n",
    "\n",
    "with $\\epsilon_t \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "Write python code to simulate one realization of this process!\n",
    "\n",
    "Hint:  You will need to use `np.random.normal` but you will not need a \"for loop\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "\n",
    "# It may be useful to first define your epsilons and then sum appropriate shifts.\n",
    "\n",
    "ts = \n",
    "\n",
    "# Note:  These asserts all passed 100000 times.\n",
    "assert(len(ts) == sample_size)\n",
    "assert((ts[1:]*ts[:-1]).mean() > 0.1)\n",
    "assert(np.abs((ts[3:]*ts[:-3]).mean()) < 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b)\n",
    "\n",
    "Plot the ACF and PACF plots of this time series.  Before making the plots, discuss what you *expect* to see with your group based on the theory covered in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c)\n",
    "\n",
    "Parameter estimation for $\\operatorname{MA}(q)$ models is tougher than for $\\operatorname{AR}(p)$ models so we will not attempt this \"by hand\".\n",
    "\n",
    "Fit an $\\operatorname{MA}(2)$ model to the data using `pm.ARIMA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = \n",
    "arima.fit(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again it might be nice to \"run all cells above\" a few times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Lynx data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lynx dataset records the number of lynx skins collected by the Hudsonâ€™s Bay Company from 1821 to 1934."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.datasets import load_lynx\n",
    "y = load_lynx(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all but the last 20 years as our training set.\n",
    "y_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train.index, y_train.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a)  \n",
    "\n",
    "Plot the ACF and PACF plots of the training data.  What models do they suggest we might try?  Discuss with your group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly $\\operatorname{PACF}(1)$ is positive and $\\operatorname{PACF}(2)$ is negative. Think about what that means in terms of the regression coefficients!  This is what is driving the \"boom/bust\" cycle we observe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b)\n",
    "\n",
    "`pm.auto_arima` will search through different values of $(p,d,q)$ and attempt to find one that minimizes the [Akaike information criterion (AIC)](https://en.wikipedia.org/wiki/Akaike_information_criterion).  This information theoretic approach to model selection is an alternative to cross validation (it is an approximation of leave-out-one cross validation error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model = auto_arima(y_train, trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we predict the next four values beyond the training data:\n",
    "\n",
    "arima_model.predict(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`auto_arima` has selected a model with both an $\\operatorname{AR}(2)$ component and an $\\operatorname{MA}(2)$ component.  In other words, the model is:\n",
    "\n",
    "$$\n",
    "y_{t} = \\beta_1 y_{t-1} + \\beta_2 y_{t-2} +  \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2}\n",
    "$$\n",
    "\n",
    "where $\\epsilon_t$ are Gaussian white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c)\n",
    "\n",
    "In this last section we will compare the following 4 models using time series cross validation:\n",
    "\n",
    "* Model 0: A baseline \"Naive\" forecast\n",
    "* Model 1: An $\\operatorname{AR}(2)$ model which regresses $y_t$ on $y_{t-1}, y_{t-2}$\n",
    "* Model 2: A model which regresses $y_t$ on $y_{t-1}, y_{t-2}$, and $y_{t-8}$.  This model is suggested by the significant value of $\\operatorname{PACF}(8)$.\n",
    "* Model 3: Whatever model is selected by `auto_arima` in each fold.  Note that we are allowing the order to change as we see new data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our cross validation scheme:\n",
    "\n",
    "* We are focused on a forecasting horizon of one year.\n",
    "* We will reserve the last 10 years as a testing set, so we will not look at them during cross validation.\n",
    "* In each fold:\n",
    "    * Fold 1: Train on [:-10] and then predict [-10].\n",
    "    * Fold 2: Train on [:-9] and predict [-9].\n",
    "    * $\\vdots$\n",
    "    * Fold 10: Train on [:-1] and predict on [-1]\n",
    "* Store these predictions and compare them to y_train[-10:].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model2 = LinearRegression()\n",
    "\n",
    "model0_preds = []\n",
    "model1_preds = []\n",
    "model2_preds = []\n",
    "model3_preds = []\n",
    "\n",
    "# Model 2 is \"custom\" so we will fit it using linear regression.\n",
    "design_matrix, targets = X_y_for_lags(y_train.values, 8)\n",
    "\n",
    "# Note:  you could also use TimeSeriesSplit here, but I find it more trouble than it is worth.\n",
    "for i in range(-10, 0):\n",
    "    X_tt, y_tt = \n",
    "\n",
    "    # The holdout data should have a single row!\n",
    "    X_ho, y_ho = \n",
    "\n",
    "    # X_tt_1 is used for model 1 and should only use lags 1 and 2\n",
    "    X_tt_1 = \n",
    "\n",
    "    # X_tt_2 is used for model 2 an should only use lags 1, 2 and 8\n",
    "    X_tt_2 =\n",
    "\n",
    "    # Again, these should have a single row.\n",
    "    X_ho_1 = \n",
    "    X_ho_2 = \n",
    "\n",
    "    # Fit the models\n",
    "    # Note:  you could alternatively define model1 using pm.ARIMA\n",
    "    model1.fit(X_tt_1, y_tt)\n",
    "    model2.fit(X_tt_2, y_tt)\n",
    "    # model3 is auto_arima\n",
    "    model3 = \n",
    "\n",
    "    # Model 0 is the naive forecast:  just predict the last training value.\n",
    "    model0_preds.append()\n",
    "\n",
    "    # Model 1 and 2 are linear regressions.  You should know how to predict on the\n",
    "    # hold out set.\n",
    "    model1_preds.append()\n",
    "    model2_preds.append()\n",
    "\n",
    "    # Model 3 is the auto_arima selected model.  We need one prediction beyond the training set.\n",
    "    model3_preds.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train.index[-20:], y_train.iloc[-20:], label = 'data')\n",
    "plt.plot(y_train.index[-10:], model0_preds, label = 'Naive')\n",
    "plt.plot(y_train.index[-10:], model1_preds, label = 'AR(2)')\n",
    "plt.plot(y_train.index[-10:], model2_preds, label = 'Custom AR')\n",
    "plt.plot(y_train.index[-10:], model3_preds, label = 'auto_arima')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these look especially great, but let's see if we at least found a model which outperforms our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse0 = mse(y_train[-10:],model0_preds)\n",
    "mse1 = mse(y_train[-10:],model1_preds)\n",
    "mse2 = mse(y_train[-10:],model2_preds)\n",
    "mse3 = mse(y_train[-10:],model3_preds)\n",
    "\n",
    "unordered_dict = {'Model 0':mse0, 'Model 1':mse1, 'Model 2':mse2, 'Model 3':mse3}\n",
    "ordered_dict = dict(sorted(unordered_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "ordered_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order of decreasing MSE we have:\n",
    "\n",
    "* Model 0: the naive baseline coming in last place\n",
    "* Model 3: `auto_arima`\n",
    "* Model 1: the $\\operatorname{AR}(2)$\n",
    "* Model 2: the \"custom\" $\\operatorname{AR}$ model wins the prize!\n",
    "\n",
    "See how model 2 does on the testing set! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how we did visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y.index[-20:], y.iloc[-20:], label = 'data')\n",
    "plt.plot(y.index[-10:], model2_preds, label = 'final model')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
